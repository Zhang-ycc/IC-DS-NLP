{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Representation in Biomedical Domain\n",
    "\n",
    "Before you start, please make sure you have read this notebook. You are encouraged to follow the recommendations but you are also free to develop your own solution from scratch. \n",
    "\n",
    "## Marking Scheme\n",
    "\n",
    "- Biomedical imaging project: 40%\n",
    "    - 20%: accuracy of the final model on the test set\n",
    "    - 20%: rationale of model design and final report\n",
    "- Natural language processing project: 40%\n",
    "    - 30%: completeness of the project\n",
    "    - 10%: final report\n",
    "- Presentation skills and team work: 20%\n",
    "\n",
    "\n",
    "This project forms 40\\% of the total score for summer/winter school. The marking scheme of each part of this project is provided below with a cap of 100\\%.\n",
    "\n",
    "You are allowed to use open source libraries as long as the libraries are properly cited in the code and final report. The usage of third-party code without proper reference will be treated as plagiarism, which will not be tolerated.\n",
    "\n",
    "You are encouraged to develop the algorithms by yourselves (without using third-party code as much as possible). We will factor such effort into the marking process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Prerequisites \n",
    "\n",
    "Recommended environment\n",
    "\n",
    "- Python 3.7 or newer\n",
    "- Free disk space: 100GB\n",
    "\n",
    "Download the data\n",
    "\n",
    "```sh\n",
    "# navigate to the data folder\n",
    "cd data\n",
    "\n",
    "# download the data file\n",
    "# which is also available at https://www.semanticscholar.org/cord19/download\n",
    "wget https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2021-07-26/document_parses.tar.gz\n",
    "\n",
    "# decompress the file which may take several minutes\n",
    "tar -xf document_parses.tar.gz\n",
    "\n",
    "# which creates a folder named document_parses\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (20%): Parse the Data\n",
    "\n",
    "The JSON files are located in two sub-folders in `document_parses`. You will need to scan all JSON files and extract text (i.e. `string`) from relevant fields (e.g. body text, abstract, titles).\n",
    "\n",
    "You are encouraged to extract full article text from body text if possible. If the hardware resource is limited, you can extract from abstract or titles as alternatives. \n",
    "\n",
    "Note: The number of JSON files is around 425k so it may take more than 10 minutes to parse all documents.\n",
    "\n",
    "For more information about the dataset: https://www.semanticscholar.org/cord19/download\n",
    "\n",
    "Recommended output:\n",
    "\n",
    "- A list of text (`string`) extracted from JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing papers: 100%|██████████| 425257/425257 [13:20<00:00, 531.52paper/s] \n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# TODO: add your solution\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_data() -> list[str]:\n",
    "    \"\"\" Scans all JSON files in folder `data` and extracts full text from them.\n",
    "\n",
    "    Returns:\n",
    "       list[str]: A list containing full article text of all papers.\n",
    "    \"\"\"    \n",
    "\n",
    "    res = []\n",
    "\n",
    "    doc_dir = os.path.join(\"data\", \"document_parses\")\n",
    "    pdf_dir = os.path.join(doc_dir, \"pdf_json\")\n",
    "    pmc_dir = os.path.join(doc_dir, \"pmc_json\")\n",
    "    file_paths = [os.path.join(pdf_dir, filename) for filename in os.listdir(pdf_dir)]\n",
    "    file_paths.extend([os.path.join(pmc_dir, filename) for filename in os.listdir(pmc_dir)])\n",
    "    \n",
    "    with tqdm(file_paths, desc=\"Parsing papers\", unit=\"paper\") as pbar:\n",
    "        for file_path in pbar:\n",
    "            with open(file_path, encoding='utf-8') as f:\n",
    "                paper = json.load(f)\n",
    "                body_text = paper['body_text']\n",
    "                res.append('\\n'.join(para['text'] for para in body_text))\n",
    "\n",
    "    return res\n",
    "\n",
    "full_texts = parse_data()\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425257\n",
      "Digital technologies have provided support in diverse policy, business, and societal application areas in the COVID-19 outbreak, such as pandemic management (Radanliev et al., 2020b) , corporate communications (Camilleri, 2020) , analysis of research data (Radanliev et al., 2020a) , and education (Crawford et al., 2020) . COVID-19 started as a global infectious disease in the spring of 2020, but the necessary measures to control the virus went beyond treatment and were also directed against its spread. Thus, for months, all interpersonal relationships were characterized by social distancing, and the pandemic raised not only medical but also social, economic and technological issues, among others. Higher education was one domain that the pandemic affected radically (Nuere and de Miguel, 2020; Watermeyer et al., 2020) . During the worldwide lockdown, higher educational institutions had to immediately switch their activities from the classroom and the campus to a virtual space, which was the only alternative to a complete incapacity to act (Crawford et al., 2020; Kamarianos et al., 2020; Karalis and Raikou, 2020; Owusu-Fordjour et al., 2020; Shah et al., 2020) .\n",
      "University students represent a generation of digital natives for whom this steady switch from the real to the virtual world should not pose any operational challenge (Carlson, 2005; Berk, 2009; Jones et al., 2010) . However, research indicates that students show differences according to discipline, such as subject matter (Biglan, 1973; Neumann, 2001) or facets of digital literacy and competency (Nelson et al., 2011) , which should be taken into consideration when developing digital learning environments and approaches. The issue of whether and how teaching and learning differs across disciplines has however long been neglected in academic discourse (Neumann, 2001) . Furthermore, as in any field, the successful introduction of technology into existing processes -such as the phenomenon that occurred in the COVID-19 pandemic during the springsummer 2020 semester (or the so-called COVID-19 semester)can only be guaranteed if teachers and students show or develop appropriate attitudes, beliefs, behaviors and habits (Al-alak and Alnawas, 2011; Al-Harbi, 2011) .\n",
      "Starting from the circumstances of the pandemic -a rapid transition to fully technology-mediated teaching for students taking different subjects, with no alternative, accompanied by several months of social isolation -in this paper, we ask:\n",
      "Do the acceptance toward completely technology-mediated teaching differ, depending on the discipline of study?\n",
      "Did the students' acceptance toward completely technologymediated teaching change over time during the COVID-19 semester?\n",
      "To address the research questions, we empirically examine the acceptance of technology-mediated teaching by students during the COVID-19 semester in the spring-summer of 2020. We follow the suggestion of Neumann (2001) that \"the strong influence of disciplines on [. . .] students' learning\" creates the need \"disciplines to be subjected to greater systematic study, especially regarding their effect on the quality of teaching and learning in higher education, \" and present, analyze and discuss the collected data from 875 responses gathered from students of two disciplines (information systems [IS] and music and arts [M&A] ) at four points in time.\n",
      "For our empirical investigation, we apply an extended version of the Technology Acceptance Model (TAM). Technology acceptance is a main topic in information systems (IS) research, and TAM is a widely used approach to investigating a subject's attitude and adoption behavior, inter alia in university context (Venkatesh and Davis, 2000; Lee et al., 2005; Pituch and Lee, 2006; Al-Azawei et al., 2017) . For the purpose of this study, the model allows us to investigate the acceptance of technology-mediated teaching, especially regarding certain aspects (usefulness, ease of use and enjoyment) that are relevant for students. Our goal is to understand not only whether students accept technologymediated teaching but also what key aspects are decisive for the future design of technology-mediated teaching environments. For this reason, we apply the TAM, as well as look beyond the model at the research on the advantages and the disadvantages of technology-mediated teaching and the extended TAM, using three new variables to be able to analyze the construct of perceived usefulness for students during the COVID-19 season in more detail and depth.\n",
      "This paper is organized as follows: In Section \"Theoretical Framework, \" we discuss the theoretical foundations of our investigation. The design and the procedure of the study, as well as the measures and data analysis are presented in Section \"Materials and Methods.\" The presentation of the results is the focus of Section \"Results.\" We discuss the results of the analysis in Section \"Discussion of the Results\" and provide implications for teaching practice and organization, educational technology, and research in Section \"Implications for Teaching Practice, Educational Technology and Further Research.\" We conclude this paper in Section \"Conclusion\" with a short summary, limitations of the study, and remarks on future studies.\n",
      "The TAM is one of the most widely investigated and applied models of technology acceptance. Perceived usefulness (PU) and perceived ease of use (PEOU) are the two decisive variables for a person's attitude (ATT) toward a used technology, which in turn affects the actual system use. PU depicts a person's subjective sensation that the application of a certain technology improves individual work performance, while PEOU measures a person's perception of how much effort the usage of the new technology requires. Both variables are influenced by diverse external variables, such as job relevance, subjective norm or output quality (Venkatesh and Davis, 2000) . Davis et al. (1989) adjusted the model by adding a person's behavioral intention (BI) as mediator between ATT and actual system use. Table 1 shows an overview of the research on the TAM in the e-learning context. For the e-learning context, Lee et al. (2005) added perceived enjoyment (PE) as an intrinsic motivator, in addition to PU and PEOU, to TAM constructs. Šumak et al. (2011) conducted a meta-analysis and found that the TAM was the most applied model in e-learning and that the size of the causal effects between individual TAM-related factors depends on the type of user and the type of e-learning technology.\n",
      "For our study, we adapt the research model of Lee et al. (2005) , as presented in Figure 1 .\n",
      "Consistent with the findings of prior studies (cf. Davis et al., 1989; Lee et al., 2005) , we expect the relations among the constructs to exhibit significant strength (for the list of the hypotheses, cf. Attachment 1). However, in our discussion, we take into account that the TAM in e-learning is usually researched in cases where blended learning or e-learning is an additional part of face-to-face teaching, whereas in the COVID-19 semester, virtual teaching and learning was Mohammadi, 2015 quality features, perceived ease of use, perceived usefulness on users' intentions, satisfaction, usability toward use of e-learning SEM, path analysis 'Intention\" and \"user satisfaction\" both had positive effects on actual use of e-learning. \"System quality\" and \"information quality\" were found to be the primary factors driving users' intentions and satisfaction toward use of e-learning. \"Perceived usefulness\" mediated the relationship between ease of use and users' intentions Al-Azawei et al., 2017 e-learning self-efficacy, perceived satisfaction, learning styles, perceived usefulness, perceived ease of use, intention to use PLS SEM Highlights the integration of perceived satisfaction and technology acceptance in accordance with psychological traits and learner beliefs. Model achieved an acceptable fit and successfully integrated intention to use (ITU) and perceived satisfaction the only channel used to convey content. We examine the measurement model and the structural model and then compare the results over time and for the two student populations (IS and M&A).\n",
      "Acceptance Over Time Venkatesh and Davis (2000) tested an extended TAM (TAM2) in four longitudinal studies and introduced experience as a relevant influencing factor that is important for understanding the changes in PU over time, whereby experience in general reflects an opportunity to use a technology and is typically operationalized as the passage of time from an individual's initial use of a technology. Based on the TAM, Venkatesh et al. (2003) developed UTAUT and tested it in a longitudinal field study. Venkatesh et al. (2012) introduced three new constructs to UTAUT, measured users' experience and investigated its influence on the users' acceptance and habits. Davis and Wong (2007) applied TAM2 in an educational context and measured users' experience in relation to the actual student usage (system use) of an e-learning system. They pointed out the complex underlying interactions during e-learning adoption processes and recommended a longitudinal design as appropriate for future studies. Pynoo et al. (2011) applied UTAUT in the educational context to investigate the acceptance of digital learning environments and found differences over time; they also pointed out that the usefulness of digital learning environments should be demonstrated to maximize its use.\n",
      "In contrast to other studies, our study does not focus on a specific technology but on the experience with the technology-mediated teaching in the COVID-19 context. We expect and show within this context that students gain experience during the semester, which will lead to measurable changes in their acceptance. Hu et al. (1999) define a set of users' characteristics as one factor that can be used to explain, predict and effectively manage technology acceptance. Biglan (1973) points out the characteristics of academic matter, according to which the strongest differences between the \"hard\" (e.g., engineering sciences) and the \"soft\" sciences (e.g., social sciences, educational sciences, and humanities) can be identified. Vo et al. (2020) investigated the effects of blended learning on student learning performance and compared the output of students in hard and soft disciplines. According to their study, students in soft disciplines perform better than their peers in hard disciplines when courses are designed in the blended learning modality. Cameron (2017) identified differences in student engagement between 'humanities' (e.g., M&A) and 'professional fields' students (such as IS). Additionally, teaching experiences are more highly regarded by humanities students than those in hard sciences (Cashin and Downey, 1995) . In the context of our study, this is expected to lead to differentiating results when lecturers had to quickly change toward virtual formats based on their diverse levels of experience with technologies. Pike et al. (2012) found that that students' academic majors are significantly related to levels of engagement, which is influenced by their acceptance and learning outcomes. Students of enterprising disciplines are more engaged than artistic discipline students. Students of soft applied knowledge (e.g., M&A) need more intensive practical training than those from the disciplines of hard applied knowledge (e.g., IS) (Neumann et al., 2002) . Here might be a major disadvantage for specific groups when virtual teaching is applied for learning.\n",
      "According to the research on the learning characteristics and the learning styles of the Net generation (born after 1980) and the Z generation (millennials), university students at the time of the COVID-19 crisis are digital natives, who can be described as tending toward independence and autonomy in their learning styles, technology savvy, interested in communicating visually and in multimedia and able to move seamlessly between real and virtual worlds (Carlson, 2005; Berk, 2009; Jones et al., 2010) .\n",
      "Despite this, it is also characteristic of this generation to view class as a social opportunity and to crave face-to face social interaction, whereby relationships, in-person conversation, interaction and collaboration are high priorities (Howe, 2000; Carlson, 2005; Ramaley and Zia, 2005) . Zheng et al. (2017) investigated lowand high-performing students in an e-learning environment and identified a significant difference in the students' perceived usefulness. Xu and Jaggars (2014) found that the typical student had more difficulty with succeeding in online courses than in face-to-face courses [compare also (Nelson et al., 2011) ; they also noted a variation across subject areas in terms of online course effectiveness].\n",
      "To the best of our knowledge, to date, no research has put the TAM in the context of the specific characteristics of a study's subjects. This is where our study can make a contribution, as we have examined two different subject groups: M&A students and IS students.\n",
      "In summary, we expect differences in the students' attitudes toward virtual learning, according to their academic subject.\n",
      "The benefits and the disadvantages of technology-mediated teaching and learning became a focal point for university research in the context of the COVID-19 crisis (Kamarianos et al., 2020; Karalis and Raikou, 2020; Owusu-Fordjour et al., 2020; Shah et al., 2020) . However, this topic is not new but one of the central research focuses in the context of learning in digital learning environments. Davis and Wong (2007) define e-learning as a global phenomenon for organizations and educational institutions, aiming to enhance students' learning experience and effectiveness in terms of the learning outcome. The benefits of e-learning have been discussed in recent research, but so far, there is no consensus on whether the outputs of e-learning are more effective than those of traditional learning formats (Derouin et al., 2005) . The most frequently stated benefits are cost efficiency, flexibility (in terms of time and place), saving time to travel to the learning location, easy access to learning materials, as well as the usefulness of learning materials for a longer period (Welsh et al., 2003; Brown et al., 2006; Hameed et al., 2008; Jefferson and Arnold, 2009; Hill and Wouters, 2010; Al-Qahtani and Higgins, 2013; Becker et al., 2013) , or the potential to offer personalized learning according to the learner's specific needs (Berge and Giles, 2006) .\n",
      "On the negative side, technology-mediated learning lacks direct social interaction and a personal touch and has the potential to socially isolate the learner or at least to negatively influence social aspects of learning processes (Gimson and Bell, 2007; Hameed et al., 2008; Al-Qahtani and Higgins, 2013; Becker et al., 2013) . Socially isolated learning can negatively influence the development of learners' communication skills, as well as change communication conditions, including the lack of support and feedback using non-verbal cues or by observing the interactions of others, as well as the lack of social and cognitive presence and teacher's involvement (Al-Qahtani and Higgins, 2013) . Furthermore, learners are insecure about their learning in the absence of regular contact to the teachers (Al-Qahtani and Higgins, 2013). Technology-mediated teaching and learning requires self-motivation, time management and a focused approach and self-directed learning and organization skills of learners (Hameed et al., 2008; Jefferson and Arnold, 2009 ). According to Al-Qahtani and Higgins (2013), these requirements arise partly from the conditions of social isolation and lack of direct social interaction, which means that the learner must have a relatively strong motivation to mitigate this effect.\n",
      "During the lockdown of the universities the expectation was that most of the young students will not have any difficulty in switching to online teaching, which is indeed confirmed by actual findings (e.g., Kamarianos et al., 2020) . Shah et al. (2020) point out the numerous and immediately apparent benefits of transferring learning to the virtual world: free exchange of information, access to lectures and presentations at conferences that used to involve considerable travel costs, webinars and online discussions, reduction of time inefficiency associated with travel and increased commitment. Owusu-Fordjour et al. (2020) identify negative effects, e.g., learning at home can be ineffective because of many distractions, no adequate learning environment, or contact with the teacher. Less problems have been found in switching to online teaching, however, on the negative side, technical obstacles as well as lack of communication and cooperation, difficulties to concentrate, too many screen-time, lack of logistical infrastructure, non-physical presence, more workload and the loss of lab courses and the general restriction of social contact have been pointed out as important during the crisis. To the positive characteristics belong the easy participation in class, time savings, home comfort, the possibility to learn, new competences, attending and learning flexibility.\n",
      "We conducted a longitudinal study in four German universities using an online survey to capture students' perceptions of technology-mediated teaching throughout the COVID-19 semesters in 2020. Participants in the study were students from selected courses and programs that have been invited to voluntarily take part in the survey. To identify potential differences between disciplines, we gathered responses from different subjects being taught. We have used from the beginning defined e-mail distribution lists and the group of potential respondents remained the same throughout the study. Students were asked for their agreement to the respective statements on an administered LimeSurvey. One survey was administered at the beginning of the semester in Germany (April), two surveys during the semester (May and June), and a final survey at the end of the semester (July 2020).\n",
      "The study focused on two main theoretical constructs: (1) (technology) acceptance of e-learning (see Section \"Technology Acceptance Model\") and (2) the benefits and disadvantages of e-learning compared with face-to-face or blended learning (see Section \"Benefits and Disadvantages of E-Learning\"). We relied on pre-tested scales when possible; however, we had to adopt these scales for our study. Furthermore, we collected demographic data and asked open-ended questions to gain deeper insights into students' perceptions over the semester.\n",
      "Concerning the first group of acceptance measurements, we used related items from former studies in a comparable context. We adopted the measurement scales for PU, PEOU, PE, ATT, and BI from Lee et al. (2005) , as the authors had already pre-tested these constructs for e-learning activities and proven their applicability. As in the original constructs, the items were measured using a 7-point Likert scale. Slight modifications were made to fit items to the investigated e-learning context.\n",
      "To address the benefits and disadvantages of e-learning, the identified factors (see Section \"Benefits and Disadvantages of E-Learning\") were operationalized through a combination of previous studies and the authors' assessment. As highlighted in the previous chapter, for time flexibility (TF), learning flexibility (LF), and social isolation (SI), the theoretical literature provides several important insights into the factors behind the advantages and disadvantages of technology-mediated teaching environments. Table 2 provides an overview of survey constructs and related measurement items as well as their sources of adoption.\n",
      "To identify differences in students' perceptions over time, we surveyed the same student populations four times during the semester. At University 1, we gathered responses from master's students in IS, while at Universities 2, 3, and 4, we surveyed participants involved in courses that are part of the music and arts curriculum (bachelor, M&A).\n",
      "We sent a link to the questionnaire throughout the semester and gathered 875 responses, of which 246 (28%) came from IS students and 629 (72%) from M&A students. We gathered 147 responses in April, 319 in May, 269 in June, and 128 in July. Of the responses, 59% (513) were received from women, 35% (310) came from men, and the remaining 62 (6%) specified another sex or provided no information. \n",
      "Data preparation and analysis were conducted in R with the Stats package, version 3.6.1. Incorrect encodings and values were filtered manually. Throughout the survey, no questions were designated as mandatory. For model testing, only constructs for which all related items were answered were used. Regression model analysis was used to test the individual models. Regression models were estimated using the ordinary least square (OLS) method. The survey constructs were calculated based on the mean values of the respective items. Given the focus of our study, we employed the students' subject as the control variable in all model constructs (see the section on the differences between student groups). A binary dummy variable indicating the M&A group was used. Table 3 provides descriptive details for the model constructs. The constructs average values varied. The respondents assessed the ease of using technology-mediated teaching and related technologies as relatively high (avg. 5.2, SD = 1.19) and simultaneously stated that learning with digital technologies did not necessary lead to completely socially isolated work (avg. 3.47, SD = 1.57). The students were almost in agreement regarding the benefits of learning flexibility (avg. 4.92) and time flexibility (avg. 5.01).\n",
      "A comparison of the students' groups revealed that uniformity within the information systems group was larger in almost any of the respective constructs (standard deviation was lower). Moreover, we observed that the agreement was higher for the central model constructs for the group of IS students. Details are discussed in the following sections.\n",
      "To ensure the validity of the measurement constructs, two approaches were used. For the new items regarding the benefits and disadvantages of technology-mediated teaching and learning, we first employed an explorative factor analysis (EFA) to assess their suitability to measure related aspects. Apart from the developed items, we assessed the internal validity for all constructs in the model.\n",
      "Explorative factor analysis has been applied for the constructs related to technology-mediated teaching and learning validity and reliability. A principal component factor analysis with a maximal likelihood estimation rotation was performed on the collected items. The related nine items were employed in a factor analysis, resulting in three constructs. Factor 1 (time flexibility) comprised two items reported on a 7-point Likert scale that explained 30% of the variance with factor loadings from 0.652 to 0.997. Factor 2 (learning flexibility) comprised two items (instead of the three expected, compare Table 4 for the item deleted after the EFA) reported on a 7-point Likert scale that explained 12% of the variance with factor loadings from 0.573 to 0.678. Factor 3 (social isolation) comprised three items reported on a 7-point Likert scale that explained 26% of the variance, with factor loadings from 0.758 to 0.929. Following the results of the EFA, the factors social isolation and time flexibility matched our developed items for each construct. Concerning learning flexibility, the item related to the video lectures (c.f. Table 4 ) did not match to a significant extent (0.351) and was dropped accordingly. Lastly, the internal validity was assessed for all constructs. The established group of technology acceptance constructs was only tested for their internal validity through Cronbach's alphas. Table 4 provides an overview of the survey constructs internal validity and the survey items used. Apart from the PU and \n",
      "The overall results of the structural model test are shown in Figure 2 . The model accounts for 65% of the variance in ATT and 54% of the variance in BI. For all the model constructs, the significant factors were identified with the survey data. Table 5 provides an overview of the hypotheses and the related results. With the exception of H1 (PEOU -> PU), all TAM hypotheses could be verified in our sample.\n",
      "Two of the items in PU directly address the perception of the benefits or advantages of technology-mediated teaching. The third deals with the direct output of learning, which is related to its perceived effectiveness (cf . Table 4 ). Thus, we analyzed the data in view of the potential relations between the perceived benefits and disadvantages of technology-mediated teaching and PU. Based on our empirical results, we were interested in identifying the sentiments underlying students' perceptions of the usefulness of technology-mediated teaching. We therefore extended the TAM core model with the three new factors influencing PU, as presented in Figure 3 .\n",
      "Furthermore, we conducted a regression analysis of PU over time, as illustrated in Table 6 . The effects of TF, LF, and SI explained 34% of the variance in PU in the model test (Figure 3) , as well as up to 35% of the variance in PU over time (Table 6) , with a very low explanation rate in May, which was also the only month when SI had a significant effect on PU. \n",
      "To identify the differences between the two student groups, a Kruskal-Wallis test was performed. As a non-parametric test, the approach allowed us to identify differences among our subsamples of different sizes. Overall, all central model constructs vary between the student's subject. Moreover, in general compared with IS students, M&A students have more negative perceptions of almost all model constructs.\n",
      "The differences in the central model constructs were analyzed in terms of variations over time and between subject groups. Figure 3 shows the results for BI over time and between subject groups as generally higher for IS students and indicates further differences over time. For IS students, the analysis results reveal increased BI over time toward the end of the semester. For the FIGURE 2 | TAM test results, including LF, TF, and SI as influencing variables. ** Significant at the 0.01-level and *** significant at the 0.001-level.\n",
      "Frontiers in Psychology | www.frontiersin.org M&A group, we found similar increased BI over time; a slight decline was identified at the end of the semester.\n",
      "The same tendency in development over time and in significant (see Table 7 ) differences between the subject groups was observed with regard to PU, PEOU, and PE (visualized in Figures 4-6, respectively) .\n",
      "As shown in Table 8 , the model explains up to 59% of the variance in BI for IS students and up to 52% for M&A students. The effect of PU was not significant for both student groups at the beginning and at the end of semester and remained constantly non-significant for IS students. For M&A students, PU was very significant in the middle of the semester. The effect of ATT was significant in the beginning and the middle of the semester (June) for IS students but weakened over time. For M&A students, the effect of ATT also varied during the semester, being significant in the second month and at the end of the semester. The strongest and most constant significant effect was found for PE in both groups.\n",
      "In this study, we identified differences in the perceptions of the investigated subject groups and over time. The first research question (RQ1) could be answered positively: For all constructs of our model, the results show significant differences toward completely technology-mediated teaching depending on the discipline of study. In general, for all constructs, M&A students answer more negatively than IS, which leads to the conclusion that they will not accept (complete) technology-mediated teaching to the same extent as IS students. This supports, inter alia, our theoretical findings, especially the findings of Pike et al. (2012) , which emphasized that students' academic majors were significantly related to levels of engagement, which is influenced by their acceptance and learning outcomes. IS students in our study furthermore enjoyed the technology-mediated teaching more, although social isolation was the most negatively indicated by both groups. Neumann (2001) emphasizes a strong influence of disciplines on students' learning and behavior, and Nelson et al. (2011) point out differences in facets of digital literacy and competency. Our findings empirically support disciplinary differences in acceptance of technical-mediated teaching between M&A and IS students. We assume a higher acceptance of IS to be a result of the appropriateness of the medium for the subjects' content and the confidence that the content of their lecture can be conveyed technologically, as well as based on general openness toward technology-mediated teaching. The higher acceptance of virtual classroom format might also be a result of the general tendency for people to adopt familiar formats more easily (cf. Janssen et al., 2009) ; that is, in the present case, IS students were more familiar with technologies and virtual environments than M&A students, and, thus, possibly influencing the corresponding acceptance.\n",
      "To answer the second research question (RQ2), we analyzed differences over time and between the two groups. The results show that this research question was also positively answered: The students' attitudes toward completely technology-mediated teaching changed over time during the COVID-19 semester. Especially in the last month of the semester, a decline in all constructs was apparent for the M&A group. One reason for this finding may be that at this time, the loosening of social isolation had begun, and face-to-face teaching was possible again, clearly demonstrating its advantages for this group compared with completely technology-mediated teaching. A reason for M&A students' perception of technology-mediated teaching as much less suitable for conveying their learning content could be the lack of opportunities for laboratories and studios, audience response (in music and theater), and practical work in technology-mediated teaching, which are a main focus of their curriculum. We assume that the type of knowledge imparted in the curriculum is also responsible for these differences.\n",
      "Further, in the context of RQ2, we measured the effect of PE, ATT, and PU on BI separately for both groups using a regression analysis. Even if both groups did not rate the PU as high, the usefulness of technology-mediated teaching did not significantly affect the intentional behavior for any of the months of the survey. PU seemed to be important only for M&A students in the middle of the semester. This could be explained by the fact that at this time, M&A students had gained enough experience and recognized that the contents of their study cannot be transferred properly enough in a technology-mediated teaching environment. The intrinsic factor -enjoyment -however, has a decisive importance, with the remaining strong influencing effect for both groups. Further, the results show that PE was much lower for M&A students. This should be an object of further investigation focusing on variables influencing enjoyment of technology-mediated teaching. To address the special situation during this empirical study, the attitude toward technologymediated teaching was placed in a close relation to the COVID-19 crisis. The effects on BI over time should therefore also be discussed in the context of the crisis. In the middle of the semester, the BI of both groups was significantly affected by the perception of the students regarding the influence of the crisis on the future digitalization of learning processes as well as on the current semester. At the end of the semester, however, IS and M&A students' responses developed in different directionsthe experiences of IS students reduced this significant effect, although for the second group, the effect remained significant at the end. For this group, the lessons learned during the crisis are also more negative.\n",
      "Besides the results related to RQ1 and RQ2, we provided results with regard to the TAM, which are in alignment with the results of our main theoretical underlying basis, Lee et al. (2005) as well as Venkatesh and Davis (2000) . Significant effects could be confirmed in TAM core constructs. We identified in contrast to prior research an inverse effect of PEOU on PU. This might be explained by the fact that this was conducted during the COVID-19 situation, not voluntary, and we did not question the use of a specific technology, but rather technology-mediated teaching in general.\n",
      "We identified a change of acceptance over time. Shehzadi et al. (2020) investigated the influence of e-learning of Pakistani public and private university students on their satisfaction in the context of the pandemic. Therein, a positive dependence of students' satisfaction with information and communication technologies, e-service quality, and e-information quality as influencing factors of students' e-learning experience was identified. This implies that specific technologies, the service quality, which is, for example, technological smoothness and a high degree of usability, as well as teacher and teaching characteristics, might also be decisive factors for consideration when (re)designing technology-mediated teaching and learning and, thus, addressing student acceptance.\n",
      "We extended prior research introducing the new variables LF, TF, and SI to TAM and showed how they influence the PU of technology-mediated teaching learning. The possibilities to learn from home, save travel time, and access (video-recorded) lectures independently of time and place are universal benefits of technology-mediated teaching and learning that have gained importance under the special conditions of the lockdown period. Thus, it is not surprising that LF and TF were positively related to PU. The effect of LF was identified as significant in June ( Table 6) . TF had a strong effect during the whole lockdown period. Regarding the perceived disadvantages of technologymediated teaching, our results show that SI had a surprisingly positive effect on PU. This could be explained by the situation of the complete lockdown, without alternatives to learning and direct exchange. There is evidence that the willingness to perceive technology-mediated teaching and learning as equivalent to faceto-face teaching and learning is greatest when offered without alternatives (Mehra and Omidian, 2011) . The impact of SI on PU was strongest in the second month of the lockdown. This may be the result of the overall phase characteristics: during the second time, it became clear that the crisis would last longer, but the frustration about the social isolation was not yet too great by comparison.\n",
      "The results of this study on technology acceptance during the virtual COVID-19 semester in Germany are important in both the short and the long term. We point out three areas of implications: teaching practice and organization, educational technology, and research.\n",
      "Our study was conducted in a situation of immediate switch from physical presence to technology-mediated teaching. The extreme circumstances were a big challenge; however, they provided important evidence about technology-mediated teaching at universities. In the current course of the pandemic, the fallwinter 20/21 semester is equally or at least partially technologymediated. In this respect, the findings can help improve teaching directly, especially regarding the differences in the perceptions of the subjects of study.\n",
      "The differences between the student groups need to be taken into consideration by the teachers when designing virtual teaching and learning environments and conducting teaching. For example, different formats, such as breakout sessions in smaller groups, could be used. Furthermore, specific sensitization to the advantages or necessity of the formats can be applied or the degree of interactivity within the sessions adjusted. To this end, teachers should develop competencies, not only regarding the use of technical tools but also new didactic and methodological skills. Further, the overlap of technological, pedagogical and content knowledge leads to new kinds of interrelated knowledge (Mishra and Koehler, 2006; Archambault and Crippen, 2009; Schmid et al., 2020) , which are gaining importance in the context of teachers' education and professional development. The transfer of knowledge through teaching must not occur in such a way that a single technique implies innovation. It is much more challenging for lecturers to demonstrate their methodological and professional competencies through the use of media in the same way as in face-to-face teaching. The initial experiences during the COVID-19 lockdown have shown both possibilities and limitations. The students' direct feedback is all the more important to better exploit the potential of technology-mediated teaching in the future.\n",
      "In the long term, not only direct teaching practices but also the organization of the teaching processes at the universities as a whole should be taken into consideration. Customized approaches, which differ in respective share of online and offline teaching and learning formats, should be considered for students of different subjects. Whereas, for example, IS students are more familiar with virtual environments, it is assumed that they are more likely to accept and manage the switch to fully virtual learning formats. By contrast, M&A students who are generally assumed to be less familiar with virtual environments may show less acceptance of related formats. Moreover, the appropriateness of virtual teaching and learning may also generally vary among subjects. The acceptance of virtual learning formats should not be considered as similar for all students simply referring to their age/generation. We argue for a consideration of their familiarity and competences with related technologies as well as their technological affinity, which varies among subjects. Moreover, we surmise that personal interaction may not be fully substituted through virtual formats. Hybrid teaching forms seem to become most promising for the future of learning and teaching at universities (Vladova et al., 2020) . Therefore, administrative and organizational changes and reorganization of (well established) practices become necessary. These will involve adjustment and further development of the curriculum, stable and trustful technological infrastructure, organization of learning results assessment, as well as the development of a new culture of technology-mediated teaching, including netiquette, behavioral norms, and standards.\n",
      "The differences between the student groups clearly show that the use of technologies and the design of technology-mediated teaching offerings should address the specific needs of different study subjects. At the time of the study, communication platforms such as Zoom, Cisco Webex, or Big Blue Button were mainly used for teaching, as well as Moodle as a learning platform for organization of the teaching process. Against this background, the direct user feedback in our study includes important hints for educational technology (EdTech) companies. Currently, these companies mostly focus on the development of learning courses for individual use, pointing out the role of artificial intelligence (AI) and learning analytics. However, the results show the immense importance of the differences in the field of study during the transfer of knowledge in an academic environment. This can be addressed by short-and long-term solutions and may lead to innovative concepts and products, whereby the role of the teacher remains central for the transfer of specific study content. However, students can acquire different content in a completely self-directed and self-organized way. The curriculum of the two groups in our study can be used, among other things, to identify the subject-specific needs of the students.\n",
      "In the long term, the effects of LF, TF, and SI should be empirically tested and investigated by further research in a COVID-19 neutral situation. Furthermore, the changes in the TAM constructs over time refer to the influence of experience within the acceptance model in education. Thus, future research should investigate whether this experience can influence students' habits and, through this, their acceptance of face-to-face teaching. This is relevant for the phase of returning to direct face-to-face teaching after the crisis, but much more in the long term as university teaching becomes increasingly technology-mediated.\n",
      "We also identified implications for further research in the context of knowledge management. The results of the study indicate a relationship between the nature of knowledge transferred during the teaching process and the acceptance of technology-mediated teaching. When the shift to the technologymediated learning environment is considered, the nature of knowledge and how it is transferred comes to the forefront (Vladova et al., 2020) . The knowledge management literature points out the critical distinction between tacit knowledge (person-bound) and explicit knowledge (not person-bound) (Polanyi, 1966) . Whereas explicit knowledge can be transferred in the context of communication processes with the help of numbers, pictures, or language, tacit knowledge is personal and context-specific (Nonaka and Takeuchi, 1995) . Therefore, tacit knowledge is difficult to communicate (Nonaka and Takeuchi, 1995) and can be transferred only partly and by common application and practice. For example, Polanyi (1958, p. 92) posits: \"Although the expert (. . .) can indicate their clues and formulate their maxims, they know many more things than they can tell, knowing them only in practice, as instrumental particulars, and not explicitly, as objects.\"\n",
      "Next, during our data analysis, we found some implications for research on the topic of innovation diffusion (Rogers, 2010) , as IS students can probably be described as early adaptors and M&A students as the late majority. IS-students can thus be used as a test audience as well as ambassadors for a new learning technology solution. Thus, they would have a trendsetting role within universities. Thanks to their high acceptance, new technologies can be tried out without fear of resistance and their advantages can be recognized.\n",
      "We also believe that our study could be of interest in the interdisciplinary research field, especially in the context of digital-mediated team, net, and project work. At this point, the experiences and needs of M&A students are especially important to explore. Experiments as well as surveys on these types of teamwork in the university context can provide necessary information on how technology-mediated teaching should be appropriately designed for this user group. This necessitates scientific collaboration between work psychologists, computer scientists and educators.\n",
      "Although a study of this scale cannot be wholly representative of the entire higher education sector, it has provided views from two different disciplines, that is, M&A as well as IS, on the acceptance of technology-mediated teaching and learning in four universities in Germany. Motivated by the need to understand the underlying drivers of student adoption of digital-mediated learning during the COVID-19 semester, we applied the TAM in a longitudinal study and incorporated three new variables (LF, TF, and SI) influencing PU into the TAM. Furthermore, we identified differences between the subject groups regarding their perceived acceptance of digital-mediated teaching and showed the changes in BI over time for both student groups. We used a validated construct for acceptance. However, as we were aware of the specifics of the situation -social isolation and no alternative to the use of technology -we first tested the hypotheses using our sample.\n",
      "Our study also has some limitations. First, it was conducted under the special circumstances of complete social isolation in every area of life, which has an influence on the results. Furthermore, we summarized the M&A group in the evaluation without consideration for the differences within it (e.g., music, theater, architecture, visual communication). Given the urgency and the circumstances of the situation of our empirical research context, we furthermore did not have the opportunity to directly examine the organizational situation at the participating universities. However, we included questions about digital platforms and tolls, as well as open-ended questions about students' perceptions of the performance of their teachers. Thus, we addressed organizational and technical issues and their impact on student acceptance. The answers to these questions are not the focus of this paper; however, they will help us to place the model in connection with the specific framework conditions at the universities and to analyze the answers more in depth.\n",
      "In following up on our data analysis, our future research will especially address the changes on the individual level over time, further data collection in the current semester (fall-winter 20/21), and the analysis of the gathered qualitative data of the answers to the open-ended questions. These efforts will allow us to gain further information on students' perceptions of technologymediated teaching during the semester.\n",
      "The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.\n",
      "Ethical approval was not provided for this study on human participants because this was an anonymous survey, we used the own server for data administration. The participants provided their informed consent to participate in this study.\n",
      "GV developed the idea for this empirical research and was involved in all steps of the study and the manuscript preparation. GV and AU prepared the instrument applied in the empirical study. Both prepared a large part of the introduction, theory, and discussion of the results. GV was mainly responsible for the implications, AU for the conclusion. BB carried out the data analysis and described its procedure and results. NG was actively involved in the implementation of the survey and was responsible for the internal review process. All authors contributed to the article and approved the submitted version.\n",
      "This work has been partly funded by the Federal Ministry of Education and Research of Germany (BMBF) under grant no. 16DII127 (\"Deutsches Internet-Institut\").\n"
     ]
    }
   ],
   "source": [
    "print(len(full_texts))\n",
    "print(full_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (30%): Tokenization\n",
    "\n",
    "Traverse the extracted text and segment the text into words (or tokens).\n",
    "\n",
    "The following tracks can be developed in independentely. You are encouraged to divide the workload to each team member.\n",
    "\n",
    "Recommended output:\n",
    "\n",
    "- Tokenizer(s) that is able to tokenize any input text.\n",
    "\n",
    "Note: Because of the computation complexity of tokenizers, it may take hours/days to process all documents. Which tokenizer is more efficient? Any idea to speedup?\n",
    "\n",
    "### Track 2.1 (10%): Use split()\n",
    "\n",
    "Use the standard `split()` by Python.\n",
    "\n",
    "### Track 2.2 (10%): Use NLTK or SciSpaCy\n",
    "\n",
    "NLTK tokenizer: https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "SciSpaCy: https://github.com/allenai/scispacy\n",
    "\n",
    "Note: You may need to install NLTK and SpaCy so please refer to their websites for installation instructions.\n",
    "\n",
    "### Track 2.3 (10%): Use Byte-Pair Encoding (BPE)\n",
    "\n",
    "Byte-Pair Encoding (BPE): https://huggingface.co/transformers/tokenizer_summary.html\n",
    "\n",
    "Note: You may need to install Huggingface's transformers so please refer to its website for installation instructions.\n",
    "\n",
    "### Track 2.4 (Bonus +5%): Build new Byte-Pair Encoding (BPE)\n",
    "\n",
    "This track may be dependent on track 2.3.\n",
    "\n",
    "The above pre-built tokenization methods may not be suitable for biomedical domain as the words/tokens (e.g. diseases, sympotoms, chemicals, medications, phenotypes, genotypes etc.) can be very different from the words/tokens commonly used in daily life. Can you build and train a new BPE model for biomedical domain in particular?\n",
    "\n",
    "### Open Question (Optional):\n",
    "\n",
    "- What are the pros and cons of the above tokenizers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e1ddc2e8fd45b1a8b440a053b96998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenize:   0%|          | 0/425257 [00:00<?, ?text/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<2031501 unique tokens: ['0', '001', '01', '1', '12']...>\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# TODO: add your solution\n",
    "\n",
    "# Track 2.1\n",
    "\n",
    "import re\n",
    "from gensim import corpora\n",
    "\n",
    "def tokenizer_1():\n",
    "    res = []\n",
    "    for text in tqdm(full_texts, desc=\"tokenize\", unit=\"text\"):\n",
    "        res.append([word for word in re.split(r'\\W+', text.lower()) if word != ''])\n",
    "    return res\n",
    "\n",
    "texts = tokenizer_1()\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('token.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(dictionary.doc2idx(re.split(r'\\W+', full_texts[0].lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: token2id id2token\n",
    "\"\"\"\n",
    "\n",
    "class TokenizerSplit(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dictionary = None\n",
    "\n",
    "    def tokenize(self, in_texts):\n",
    "        res = []\n",
    "        for text in tqdm(in_texts, desc=\"tokenize\", unit=\"text\"):\n",
    "            res.append([word for word in re.split(r'\\W+', text.lower()) if word != ''])\n",
    "        self.dictionary = corpora.Dictionary(res)\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self.dictionary.doc2idx([word for word in re.split(r'\\W+', text.lower()) if word != ''])\n",
    "\n",
    "    def decode(self, cor):\n",
    "        text = ''\n",
    "        for token_id in cor:\n",
    "            text += dictionary.id2token(cor)\n",
    "        return text\n",
    "\n",
    "    def getTokenId(self, word):\n",
    "        return dictionary.token2id(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/zhangyuechen/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Track 2.2\n",
    "\n",
    "\"\"\"\"\n",
    "install nltk, run for one time\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenizer_2():\n",
    "    res = []\n",
    "    for text in tqdm(full_texts, desc=\"tokenize\", unit=\"text\"):\n",
    "        res.append([word for word in word_tokenize(text.lower()) if word != ''])\n",
    "    return res\n",
    "\n",
    "texts_2 = tokenizer_2()\n",
    "dictionary_2 = corpora.Dictionary(texts_2)\n",
    "dictionary_2.save('token_2.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TokenizerNLTK(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dictionary = None\n",
    "\n",
    "    def tokenize(self, in_texts):\n",
    "        res = []\n",
    "        for text in tqdm(in_texts, desc=\"tokenize\", unit=\"text\"):\n",
    "            res.append([word for word in word_tokenize(text.lower()) if word != ''])\n",
    "        self.dictionary = corpora.Dictionary(res)\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self.dictionary.doc2idx([word for word in re.split(r'\\W+', text.lower()) if word != ''])\n",
    "\n",
    "    def decode(self, cor):\n",
    "        text = ''\n",
    "        for token_id in cor:\n",
    "            text += dictionary.id2token(cor)\n",
    "        return text\n",
    "\n",
    "    def getTokenId(self, word):\n",
    "        return dictionary.token2id(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Track 2.3\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=20000)\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.train_from_iterator(full_texts, trainer)\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"BPETokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"BPETokenizer.json\")\n",
    "\n",
    "# print(tokenizer.get_vocab())\n",
    "print(tokenizer.get_vocab_size())\n",
    "print(tokenizer.id_to_token(19824))\n",
    "print(tokenizer.token_to_id(\"tees\"))\n",
    "\n",
    "# output = tokenizer.encode(full_texts[0])\n",
    "# print(output.tokens)\n",
    "# print(tokenizer.decode(output.ids))\n",
    "\n",
    "print(tokenizer.encode(\"diseases\").tokens)\n",
    "print(tokenizer.encode(\"symptoms\").tokens)\n",
    "print(tokenizer.encode(\"chemicals\").tokens)\n",
    "print(tokenizer.encode(\"medications\").tokens)\n",
    "print(tokenizer.encode(\"phenotypes\").tokens)\n",
    "print(tokenizer.encode(\"genotypes\").tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Track 2.3 MY BPE\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "TokenizationState = Dict[str, int]\n",
    "\"\"\" State of tokenization of text.  \n",
    "E.g., `{'i</w>': 2, 'a m </w>': 1, 'ha pp y </w>': 1, 'ha v e </w>': 1, 'a pp l e s </w>': 1 }`\n",
    "\"\"\"\n",
    "Tokens = List[Tuple[str, int]]\n",
    "\"\"\" Tokens along with their frequencies.\n",
    "E.g, `[('i</w>', 2), ('ha', 2), ('pp', 2), ('a', 2), ('m', 1), ('</w>', 5), ('y', 1), ('v', 1), ('e', 2), ('l', 1), ('s', 1)]`\n",
    "\"\"\"\n",
    "Bigram = Tuple[str]\n",
    "\"\"\" One bigram.\n",
    "E.g., ('ha', 'pp').\n",
    "\"\"\"\n",
    "\n",
    "class MyBPETokenizer:\n",
    "    def __init__(self, vocab_size=30000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token2id = dict()\n",
    "        self.id2token = dict()\n",
    "\n",
    "    def token_to_id(self, token: str) -> int:\n",
    "        return self.token2id[token]\n",
    "\n",
    "    def id_to_token(self, id: int) -> str:\n",
    "        return self.id2token[id]\n",
    "\n",
    "    def encode(self):\n",
    "        pass\n",
    "\n",
    "    def decode(self):\n",
    "        pass\n",
    "\n",
    "    def pre_tokenize(self, corpus):\n",
    "        _splitor_pattern = re.compile(R\"[^a-zA-Z']+|(?=')\")\n",
    "\n",
    "        corpus = [list(\n",
    "            filter(lambda tkn: len(tkn)>0, _splitor_pattern.split(stc.lower()))) for stc in corpus\n",
    "        ]\n",
    "        \n",
    "        return corpus\n",
    "\n",
    "    def build_bpe_vocab(self, corpus: List[str]) -> TokenizationState:\n",
    "        \"\"\" Pre-tokenizes text and build the initial tokenization state.\n",
    "\n",
    "        Args:\n",
    "            corpus (List[str]): Text to tokenize.\n",
    "\n",
    "        Returns:\n",
    "            TokenizationState: Initial tokenization state (characters split by whitespace and words appended by `</w>`).\n",
    "        \"\"\"        \n",
    "\n",
    "        tokenized_corpus = self.pre_tokenize(corpus)\n",
    "        bpe_vocab = dict()\n",
    "        for stc in tokenized_corpus:\n",
    "            for word in stc:\n",
    "                key = ' '.join(list(word)) + ' </w>'\n",
    "                bpe_vocab[key] = bpe_vocab.get(key, 0) + 1\n",
    "        return bpe_vocab\n",
    "\n",
    "    def get_bigram_freq(self, bpe_vocab: TokenizationState) -> dict[Bigram, int]:\n",
    "        \"\"\" Counts frequencies of bigrams in current tokenization state.\n",
    "\n",
    "        Args:\n",
    "            bpe_vocab (TokenizationState): Current tokenization state.\n",
    "\n",
    "        Returns:\n",
    "            dict[Bigram, int]: A dictionary from bigrams to their frequencies.\n",
    "        \"\"\"        \n",
    "\n",
    "        bigram_freq = dict()\n",
    "        for word, count in bpe_vocab.items():\n",
    "            word = word.split(' ')\n",
    "            bigrams = [(word[i], word[i+1]) for i in range(len(word)-1)]\n",
    "            for bigram in bigrams:\n",
    "                bigram_freq[bigram] = bigram_freq.get(bigram, 0) + count\n",
    "        return bigram_freq\n",
    "\n",
    "    def refresh_bpe_vocab_by_merging_bigram(self, bigram: Bigram, old_bpe_vocab: TokenizationState) -> TokenizationState:\n",
    "        \"\"\" Updates tokenization state by merging given bigram (removing whitespace).\n",
    "\n",
    "        Args:\n",
    "            bigram (Tuple): The bigram to merge.\n",
    "            old_bpe_vocab (TokenizationState): Old tokenization state.\n",
    "\n",
    "        Returns:\n",
    "            TokenizationState: New tokenization state after merging.\n",
    "        \"\"\"        \n",
    "\n",
    "        new_bpe_vocab = dict()\n",
    "        bigram_pat = re.compile(f\"((?<= )|^){bigram[0]} {bigram[1]}((?= )|$)\")\n",
    "        new_token = ''.join(bigram)\n",
    "        for old_word, count in old_bpe_vocab.items():\n",
    "            new_word = re.sub(bigram_pat, new_token, old_word)\n",
    "            new_bpe_vocab[new_word] = new_bpe_vocab.get(new_word, 0) + count\n",
    "        return new_bpe_vocab\n",
    "    \n",
    "    def get_bpe_tokens(self, bpe_vocab: TokenizationState) -> Tokens:\n",
    "        \"\"\" Returns the list of tokens along with their frequencies according to \n",
    "        the dictionary from state of tokenization to frequencies.\n",
    "\n",
    "        Args:\n",
    "            bpe_vocab (TokenizationState): The dictionary from state of tokenization to frequencies.\n",
    "\n",
    "        Returns:\n",
    "            Tokens: List of tokens along with their frequencies.\n",
    "        \"\"\"        \n",
    "\n",
    "        bpe_tokens_dict = dict()\n",
    "        for word, count in bpe_vocab.items():\n",
    "            tokens = word.split(' ')\n",
    "            for token in tokens:\n",
    "                bpe_tokens_dict[token] = bpe_tokens_dict.get(token, 0) + count\n",
    "\n",
    "        bpe_tokens = [(token, freq) for token, freq in bpe_tokens_dict.items()]\n",
    "        bpe_tokens.sort(  # sort by length, note </w> contributes only 1 to length\n",
    "            key = lambda itm: len(itm[0]) if '</w>' not in itm[0] else len(itm[0])-3,\n",
    "            reverse = True)\n",
    "\n",
    "        return bpe_tokens\n",
    "\n",
    "    def tokenize_subword(self, subword: str) -> List[str]:\n",
    "        \"\"\" Recursively splits `subword` into tokens.\n",
    "\n",
    "        Args:\n",
    "            sub_word (str): The subword to tokenize.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Tokens of given subword.\n",
    "        \"\"\"        \n",
    "        if subword == '':\n",
    "            return []\n",
    "\n",
    "        for token in self.token2id:\n",
    "            if token in subword:\n",
    "                res = token\n",
    "                left = self.tokenize_subword(subword[ : subword.index(token)])\n",
    "                right = self.tokenize_subword(subword[subword.index(token) + len(token) : ])\n",
    "                return left + [res] + right\n",
    "        \n",
    "        return ['<UNK>']\n",
    "\n",
    "    def tokenize_text(self, sentence: List[str]) -> List[str]:\n",
    "        \"\"\" Tokenizes text.\n",
    "\n",
    "        Args:\n",
    "            sentence (List[str]): The text to be tokenize.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Tokens of given text.\n",
    "        \"\"\"        \n",
    "\n",
    "        res = []\n",
    "        for word in sentence:\n",
    "            res.extend(self.tokenize_subword(word + \"</w>\"))\n",
    "        return res\n",
    "        \n",
    "    def train(self, corpus):\n",
    "        \"\"\" Trains on `corpus`, that is, constructs `token2id` and `id2token`.\n",
    "\n",
    "        Args:\n",
    "            corpus (List[str]): The training corpus.\n",
    "        \"\"\"        \n",
    "\n",
    "        training_bpe_vocab = self.build_bpe_vocab(corpus)\n",
    "        for i in range(self.vocab_size):\n",
    "            bigram_freq = self.get_bigram_freq(training_bpe_vocab)\n",
    "\n",
    "            if bigram_freq:\n",
    "                updated_bigram = max(bigram_freq, key=bigram_freq.get)\n",
    "            else:  # no bigrams left\n",
    "                print(f\"No subwords left after {i} merges!\")\n",
    "                break\n",
    "            \n",
    "            training_bpe_vocab = self.refresh_bpe_vocab_by_merging_bigram(\n",
    "                updated_bigram, training_bpe_vocab)\n",
    "\n",
    "        training_bpe_tokens = self.get_bpe_tokens(training_bpe_vocab)\n",
    "        \n",
    "        for token in training_bpe_tokens:\n",
    "            token = token[0]\n",
    "            idx = len(self.token2id)\n",
    "            self.token2id[token], self.id2token[idx] = idx, token\n",
    "\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'happy</w>': 0, 'have': 1, 'am</w>': 2, 'i</w>': 3, 'pp': 4, '</w>': 5, 'a': 6, 'l': 7, 'e': 8, 's': 9}\n",
      "['happy</w>', 'a', 'pp', 'l', 'e', 's', '</w>']\n"
     ]
    }
   ],
   "source": [
    "bpe_tokenizer = MyBPETokenizer(vocab_size=10)\n",
    "bpe_tokenizer.train([\"I am happy.\", \"I have 10 apples!\"])\n",
    "print(bpe_tokenizer.token2id)\n",
    "print(bpe_tokenizer.tokenize_text([\"happy\", \"apples\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3 (30%): Build Word Representations\n",
    "\n",
    "Build word representations for each extracted word. If the hardware resource is limited, you may limit the vocabulary size up to 10k words/tokens (or even smaller) and the dimension of representations up to 256.\n",
    "\n",
    "The following tracks can be developed independently. You are encouraged to divide the workload to each team member.\n",
    "\n",
    "### Track 3.1 (15%): Use N-gram Language Modeling\n",
    "\n",
    "N-gram Language Modeling is to predict a target word by using `n` words from previous context. Specifically,\n",
    "\n",
    "$P(w_i | w_{i-1}, w_{i-2}, ..., w_{i-n+1})$\n",
    "\n",
    "For example, given a sentence, `\"the main symptoms of COVID-19 are fever and cough\"`, if $n=7$, we use previous context `[\"the\", \"main\", \"symptoms\", \"of\", \"COVID-19\", \"are\"]` to predict the next word `\"fever\"`.\n",
    "\n",
    "More to read: https://web.stanford.edu/~jurafsky/slp3/3.pdf\n",
    "\n",
    "Recommended outputs:\n",
    "\n",
    "- A fixed vector for each word/token.\n",
    "\n",
    "### Track 3.2 (15%): Use Skip-gram with Negative Sampling\n",
    "\n",
    "In skip-gram, we use a central word to predict its context. Specifically,\n",
    "\n",
    "$P(w_{c-m}, ... w_{c-1}, w_{c+1}, ..., w_{c+m} | w_c)$\n",
    "\n",
    "As the learning objective of skip-gram is computational inefficient (summation of entire vocabulary $|V|$), negative sampling is commonly applied to accelerate the training.\n",
    "\n",
    "In negative sampling, we randomly select one word from the context as a positive sample, and randomly select $K$ words from the vocabulary as negative samples. As a result, the learning objective is updated to\n",
    "\n",
    "$L = -\\log\\sigma(u^T_{t} v_c) - \\sum_{k=1}^K\\log\\sigma(-u^T_k v_c)$, where $u_t$ is the vector embedding of positive sample from context, $u_k$ are the vector embeddings of negative samples, $v_c$ is the vector embedding of the central word, $\\sigma$ refers to the sigmoid function.\n",
    "\n",
    "More to read http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf section 4.3 and 4.4\n",
    "\n",
    "Recommended outputs:\n",
    "\n",
    "- A fixed vector for each word/token.\n",
    "\n",
    "### Track 3.3 (Bonus +5%): Use Contextualised Word Representation by Masked Language Model (MLM)\n",
    "\n",
    "BERT introduces a new language model for pre-training named Masked Language Model (MLM). The advantage of MLM is that the word representations by MLM will be contextualised.\n",
    "\n",
    "For example, \"stick\" may have different meanings in different context. By N-gram language modeling and word2vec (skip-gram, CBOW), the word representation of \"stick\" is fixed regardless of its context. However, MLM will learn the representation of \"stick\" dynamatically based on context. In other words, \"stick\" will have different representations in different context by MLM.\n",
    "\n",
    "More to read: http://jalammar.github.io/illustrated-bert/ and https://arxiv.org/pdf/1810.04805.pdf\n",
    "\n",
    "Recommended outputs:\n",
    "\n",
    "- An algorithm that is able to generate contextualised representation in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# TODO: add your solution\n",
    "\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (20%): Explore the Word Representations\n",
    "\n",
    "The following tracks can be finished independently. You are encouraged to divide workload to each team member.\n",
    "\n",
    "### Track 4.1 (5%): Visualise the word representations by t-SNE\n",
    "\n",
    "t-SNE is an algorithm to reduce dimentionality and commonly used to visualise high-dimension vectors. Use t-SNE to visualise the word representations. You may visualise up to 1000 words as t-SNE is highly computationally complex.\n",
    "\n",
    "More about t-SNE: https://lvdmaaten.github.io/tsne/\n",
    "\n",
    "Recommended output:\n",
    "\n",
    "- A diagram by t-SNE based on representations of up to 1000 words.\n",
    "\n",
    "### Track 4.2 (5%): Visualise the Word Representations of Biomedical Entities by t-SNE\n",
    "\n",
    "Instead of visualising the word representations of the entire vocabulary (or 1000 words that are selected at random), visualise the word representations of words which are biomedical entities. For example, fever, cough, diabetes etc. Based on the category of those biomedical entities, can you assign different colours to the entities and see if the entities from the same category can be clustered by t-SNE? For example, sinusitis and cough are both respirtory diseases so they should be assigned with the same colour and ideally their representations should be close to each other by t-SNE. Another example, Alzheimer and headache are neuralogical diseases which should be assigned by another colour.\n",
    "\n",
    "Examples of biomedial ontology: https://www.ebi.ac.uk/ols/ontologies/hp and https://en.wikipedia.org/wiki/International_Classification_of_Diseases\n",
    "\n",
    "Recommended output:\n",
    "\n",
    "- A diagram with colours by t-SNE based on representations of biomedical entities.\n",
    "\n",
    "### Track 4.3 (5%): Co-occurrence\n",
    "\n",
    "- What are the biomedical entities which frequently co-occur with COVID-19 (or coronavirus)?\n",
    "\n",
    "Recommended outputs:\n",
    "\n",
    "- A sorted list of biomedical entities and description on how the entities are selected and sorted.\n",
    "\n",
    "### Track 4.4 (5%): Semantic Similarity\n",
    "\n",
    "- What are the biomedical entities which have closest semantic similarity COVID-19 (or coronavirus) based on word representations?\n",
    "\n",
    "Recommended outputs:\n",
    "\n",
    "- A sorted list of biomedical entities and description on how the entities are selected and sorted.\n",
    "\n",
    "### Open Question (Optional): What else can you discover?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# TODO: add your solution\n",
    "\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 (Bonus +10%): Open Challenge: Mining Biomedical Knowledge\n",
    "\n",
    "A fundamental task in clinical/biomedical natural language processing is to extract intelligence from biomedical text corpus automatically and efficiently. More specifically, the intelligence may include biomedical entities mentioned in text, relations between biomedical entities, clinical features of patients, progression of diseases, all of which can be used to predict, understand and improve patients' outcomes. \n",
    "\n",
    "This open challenge is to build a biomedical knowledge graph based on the CORD-19 dataset and mine useful information from it. We recommend the following steps but you are also encouraged to develop your solution from scratch.\n",
    "\n",
    "### Extract Biomedical Entities from Text\n",
    "\n",
    "Extract biomedical entities (such as fever, cough, headache, lung cancer, heart attack) from text. Note that:\n",
    "\n",
    "- The biomedical entities may consist of multiple words. For example, heart attack, multiple myeloma etc.\n",
    "- The biomedical entities may be written in synoynms. For example, low blood pressure for hypotension.\n",
    "- The biomedical entities may be written in different forms. For example, smoking, smokes, smoked.\n",
    "\n",
    "### Extract Relations between Biomedical Entities\n",
    "\n",
    "Extract relations between biomedical entities based on their appearance in text. You may define a relation between biomedical entities by one or more of the following criteria:\n",
    "\n",
    "- The biomedical entities frequentely co-occuer together.\n",
    "- The biomedical entities have similar word representations.\n",
    "- The biomedical entities have clear relations based on textual narratives. For example, \"The most common symptoms for COVID-19 are fever and cough\" so we know there are relations between \"COVID-19\", \"fever\" and \"cough\".\n",
    "\n",
    "### Build a Biomedical Knowledge Graph of COVID-19\n",
    "\n",
    "Build a knoweledge graph based on the results from track 5.1 and 5.2 and visualise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# TODO: add your solution\n",
    "\n",
    "###################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee6028153bae1c310a6c17909bbeb01b64dc45f74f1d212e5f04026a0eaac9d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
